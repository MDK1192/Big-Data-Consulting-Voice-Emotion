{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collected-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(1, epochs+1):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))\n",
    "        \n",
    "def find_lr(model, loss_fn, optimizer, train_loader, init_value=1e-8, final_value=10.0, device=\"cpu\"):\n",
    "    number_in_epoch = len(train_loader) - 1\n",
    "    update_step = (final_value / init_value) ** (1 / number_in_epoch)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0][\"lr\"] = lr\n",
    "    best_loss = 0.0\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    for data in train_loader:\n",
    "        batch_num += 1\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        # Crash out if loss explodes\n",
    "\n",
    "        if batch_num > 1 and loss > 4 * best_loss:\n",
    "            if(len(log_lrs) > 20):\n",
    "                return log_lrs[10:-5], losses[10:-5]\n",
    "            else:\n",
    "                return log_lrs, losses\n",
    "\n",
    "        # Record the best loss\n",
    "\n",
    "        if loss < best_loss or batch_num == 1:\n",
    "            best_loss = loss\n",
    "\n",
    "        # Store the values\n",
    "        losses.append(loss.item())\n",
    "        log_lrs.append((lr))\n",
    "\n",
    "        # Do the backward pass and optimize\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the lr for the next step and store\n",
    "\n",
    "        lr *= update_step\n",
    "        optimizer.param_groups[0][\"lr\"] = lr\n",
    "    if(len(log_lrs) > 20):\n",
    "        return log_lrs[10:-5], losses[10:-5]\n",
    "    else:\n",
    "        return log_lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "documentary-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ESC50(Dataset):\n",
    "    def __init__(self,path):\n",
    "        # Get directory listing from path\n",
    "        files = Path(path).glob('*.wav')\n",
    "        # Iterate through the listing and create a list of tuples (filename, label)\n",
    "        self.items = [(str(f),f.name.split(\"-\")[-1].replace(\".wav\",\"\")) for f in files]\n",
    "        self.length = len(self.items)\n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.items[index]\n",
    "        audioTensor, rate = torchaudio.load(filename)\n",
    "        return (audioTensor, int(label))     \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "productive-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "bs=64\n",
    "PATH_TO_ESC50 = Path.cwd() / 'esc50'\n",
    "\n",
    "train_esc50 = ESC50(PATH_TO_ESC50 / \"audio\" /\"train\")\n",
    "valid_esc50 = ESC50(PATH_TO_ESC50 / \"audio\" /\"valid\")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_esc50, batch_size = bs, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_esc50, batch_size = bs, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reserved-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    " class AudioNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(100, 128, kernel_size=5, stride=4)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(256, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(512, 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1).view(-1, 100, 2205)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "related-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioNet(\n",
       "  (conv1): Conv1d(100, 128, kernel_size=(5,), stride=(4,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))\n",
       "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audionet = AudioNet()\n",
    "audionet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expressed-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fcd9e5afa0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(audionet.state_dict(), \"audionet.pth\")\n",
    "optimizer = optim.Adam(audionet.parameters(), lr=0.001)\n",
    "logs,losses = find_lr(audionet, nn.CrossEntropyLoss(), optimizer, train_loader, device=device)\n",
    "\n",
    "plt.plot(logs,losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broadband-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "audionet.load_state_dict(torch.load(\"audionet.pth\"))\n",
    "optimizer = optim.Adam(audionet.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unable-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-c273bbe3bad0>:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], targets).view(-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 3.17, Validation Loss: 3.70, accuracy = 0.09\n",
      "Epoch: 2, Training Loss: 3.14, Validation Loss: 3.69, accuracy = 0.09\n",
      "Epoch: 3, Training Loss: 3.11, Validation Loss: 3.68, accuracy = 0.10\n",
      "Epoch: 4, Training Loss: 3.08, Validation Loss: 3.67, accuracy = 0.10\n",
      "Epoch: 5, Training Loss: 3.05, Validation Loss: 3.66, accuracy = 0.10\n",
      "Epoch: 6, Training Loss: 3.03, Validation Loss: 3.66, accuracy = 0.10\n",
      "Epoch: 7, Training Loss: 3.00, Validation Loss: 3.66, accuracy = 0.10\n",
      "Epoch: 8, Training Loss: 2.97, Validation Loss: 3.65, accuracy = 0.10\n",
      "Epoch: 9, Training Loss: 2.95, Validation Loss: 3.64, accuracy = 0.10\n",
      "Epoch: 10, Training Loss: 2.92, Validation Loss: 3.64, accuracy = 0.10\n",
      "Epoch: 11, Training Loss: 2.91, Validation Loss: 3.64, accuracy = 0.11\n",
      "Epoch: 12, Training Loss: 2.87, Validation Loss: 3.62, accuracy = 0.10\n",
      "Epoch: 13, Training Loss: 2.85, Validation Loss: 3.62, accuracy = 0.10\n",
      "Epoch: 14, Training Loss: 2.83, Validation Loss: 3.61, accuracy = 0.10\n",
      "Epoch: 15, Training Loss: 2.80, Validation Loss: 3.61, accuracy = 0.10\n",
      "Epoch: 16, Training Loss: 2.78, Validation Loss: 3.60, accuracy = 0.10\n",
      "Epoch: 17, Training Loss: 2.75, Validation Loss: 3.59, accuracy = 0.11\n",
      "Epoch: 18, Training Loss: 2.73, Validation Loss: 3.59, accuracy = 0.10\n",
      "Epoch: 19, Training Loss: 2.71, Validation Loss: 3.59, accuracy = 0.10\n",
      "Epoch: 20, Training Loss: 2.69, Validation Loss: 3.58, accuracy = 0.11\n",
      "Epoch: 21, Training Loss: 2.67, Validation Loss: 3.58, accuracy = 0.10\n",
      "Epoch: 22, Training Loss: 2.64, Validation Loss: 3.57, accuracy = 0.10\n",
      "Epoch: 23, Training Loss: 2.62, Validation Loss: 3.57, accuracy = 0.11\n",
      "Epoch: 24, Training Loss: 2.59, Validation Loss: 3.56, accuracy = 0.10\n",
      "Epoch: 25, Training Loss: 2.58, Validation Loss: 3.56, accuracy = 0.11\n",
      "Epoch: 26, Training Loss: 2.57, Validation Loss: 3.55, accuracy = 0.12\n",
      "Epoch: 27, Training Loss: 2.54, Validation Loss: 3.55, accuracy = 0.10\n",
      "Epoch: 28, Training Loss: 2.52, Validation Loss: 3.55, accuracy = 0.12\n",
      "Epoch: 29, Training Loss: 2.50, Validation Loss: 3.54, accuracy = 0.11\n",
      "Epoch: 30, Training Loss: 2.49, Validation Loss: 3.54, accuracy = 0.12\n",
      "Epoch: 31, Training Loss: 2.46, Validation Loss: 3.53, accuracy = 0.12\n",
      "Epoch: 32, Training Loss: 2.44, Validation Loss: 3.53, accuracy = 0.12\n",
      "Epoch: 33, Training Loss: 2.44, Validation Loss: 3.53, accuracy = 0.12\n",
      "Epoch: 34, Training Loss: 2.42, Validation Loss: 3.52, accuracy = 0.12\n",
      "Epoch: 35, Training Loss: 2.39, Validation Loss: 3.52, accuracy = 0.12\n",
      "Epoch: 36, Training Loss: 2.37, Validation Loss: 3.52, accuracy = 0.12\n",
      "Epoch: 37, Training Loss: 2.35, Validation Loss: 3.52, accuracy = 0.12\n",
      "Epoch: 38, Training Loss: 2.34, Validation Loss: 3.51, accuracy = 0.12\n",
      "Epoch: 39, Training Loss: 2.33, Validation Loss: 3.51, accuracy = 0.12\n",
      "Epoch: 40, Training Loss: 2.31, Validation Loss: 3.51, accuracy = 0.13\n",
      "Epoch: 41, Training Loss: 2.29, Validation Loss: 3.50, accuracy = 0.12\n",
      "Epoch: 42, Training Loss: 2.27, Validation Loss: 3.50, accuracy = 0.12\n",
      "Epoch: 43, Training Loss: 2.26, Validation Loss: 3.49, accuracy = 0.12\n",
      "Epoch: 44, Training Loss: 2.25, Validation Loss: 3.49, accuracy = 0.12\n",
      "Epoch: 45, Training Loss: 2.23, Validation Loss: 3.49, accuracy = 0.12\n",
      "Epoch: 46, Training Loss: 2.21, Validation Loss: 3.49, accuracy = 0.13\n",
      "Epoch: 47, Training Loss: 2.20, Validation Loss: 3.48, accuracy = 0.13\n",
      "Epoch: 48, Training Loss: 2.19, Validation Loss: 3.48, accuracy = 0.13\n",
      "Epoch: 49, Training Loss: 2.17, Validation Loss: 3.48, accuracy = 0.13\n",
      "Epoch: 50, Training Loss: 2.15, Validation Loss: 3.48, accuracy = 0.13\n",
      "Epoch: 51, Training Loss: 2.14, Validation Loss: 3.47, accuracy = 0.13\n",
      "Epoch: 52, Training Loss: 2.13, Validation Loss: 3.47, accuracy = 0.13\n",
      "Epoch: 53, Training Loss: 2.11, Validation Loss: 3.47, accuracy = 0.14\n",
      "Epoch: 54, Training Loss: 2.10, Validation Loss: 3.47, accuracy = 0.14\n",
      "Epoch: 55, Training Loss: 2.09, Validation Loss: 3.46, accuracy = 0.14\n",
      "Epoch: 56, Training Loss: 2.08, Validation Loss: 3.46, accuracy = 0.13\n",
      "Epoch: 57, Training Loss: 2.07, Validation Loss: 3.46, accuracy = 0.13\n",
      "Epoch: 58, Training Loss: 2.05, Validation Loss: 3.46, accuracy = 0.14\n",
      "Epoch: 59, Training Loss: 2.04, Validation Loss: 3.45, accuracy = 0.14\n",
      "Epoch: 60, Training Loss: 2.03, Validation Loss: 3.45, accuracy = 0.14\n",
      "Epoch: 61, Training Loss: 2.01, Validation Loss: 3.45, accuracy = 0.14\n",
      "Epoch: 62, Training Loss: 2.00, Validation Loss: 3.45, accuracy = 0.14\n",
      "Epoch: 63, Training Loss: 1.99, Validation Loss: 3.45, accuracy = 0.14\n",
      "Epoch: 64, Training Loss: 1.98, Validation Loss: 3.44, accuracy = 0.14\n",
      "Epoch: 65, Training Loss: 1.97, Validation Loss: 3.44, accuracy = 0.14\n",
      "Epoch: 66, Training Loss: 1.96, Validation Loss: 3.44, accuracy = 0.13\n",
      "Epoch: 67, Training Loss: 1.94, Validation Loss: 3.44, accuracy = 0.14\n",
      "Epoch: 68, Training Loss: 1.94, Validation Loss: 3.44, accuracy = 0.14\n",
      "Epoch: 69, Training Loss: 1.92, Validation Loss: 3.43, accuracy = 0.13\n",
      "Epoch: 70, Training Loss: 1.91, Validation Loss: 3.43, accuracy = 0.14\n",
      "Epoch: 71, Training Loss: 1.90, Validation Loss: 3.43, accuracy = 0.15\n",
      "Epoch: 72, Training Loss: 1.89, Validation Loss: 3.43, accuracy = 0.14\n",
      "Epoch: 73, Training Loss: 1.87, Validation Loss: 3.43, accuracy = 0.14\n",
      "Epoch: 74, Training Loss: 1.86, Validation Loss: 3.42, accuracy = 0.14\n",
      "Epoch: 75, Training Loss: 1.86, Validation Loss: 3.42, accuracy = 0.15\n",
      "Epoch: 76, Training Loss: 1.85, Validation Loss: 3.42, accuracy = 0.14\n",
      "Epoch: 77, Training Loss: 1.83, Validation Loss: 3.42, accuracy = 0.14\n",
      "Epoch: 78, Training Loss: 1.81, Validation Loss: 3.41, accuracy = 0.15\n",
      "Epoch: 79, Training Loss: 1.80, Validation Loss: 3.41, accuracy = 0.14\n",
      "Epoch: 80, Training Loss: 1.80, Validation Loss: 3.41, accuracy = 0.15\n",
      "Epoch: 81, Training Loss: 1.79, Validation Loss: 3.41, accuracy = 0.15\n",
      "Epoch: 82, Training Loss: 1.78, Validation Loss: 3.41, accuracy = 0.15\n",
      "Epoch: 83, Training Loss: 1.76, Validation Loss: 3.41, accuracy = 0.14\n",
      "Epoch: 84, Training Loss: 1.76, Validation Loss: 3.41, accuracy = 0.14\n",
      "Epoch: 85, Training Loss: 1.76, Validation Loss: 3.41, accuracy = 0.15\n",
      "Epoch: 86, Training Loss: 1.74, Validation Loss: 3.41, accuracy = 0.15\n",
      "Epoch: 87, Training Loss: 1.73, Validation Loss: 3.41, accuracy = 0.14\n",
      "Epoch: 88, Training Loss: 1.73, Validation Loss: 3.40, accuracy = 0.15\n",
      "Epoch: 89, Training Loss: 1.70, Validation Loss: 3.40, accuracy = 0.15\n",
      "Epoch: 90, Training Loss: 1.71, Validation Loss: 3.40, accuracy = 0.14\n",
      "Epoch: 91, Training Loss: 1.69, Validation Loss: 3.39, accuracy = 0.14\n",
      "Epoch: 92, Training Loss: 1.69, Validation Loss: 3.40, accuracy = 0.14\n",
      "Epoch: 93, Training Loss: 1.67, Validation Loss: 3.39, accuracy = 0.15\n",
      "Epoch: 94, Training Loss: 1.66, Validation Loss: 3.39, accuracy = 0.15\n",
      "Epoch: 95, Training Loss: 1.65, Validation Loss: 3.39, accuracy = 0.15\n",
      "Epoch: 96, Training Loss: 1.65, Validation Loss: 3.39, accuracy = 0.16\n",
      "Epoch: 97, Training Loss: 1.64, Validation Loss: 3.39, accuracy = 0.16\n",
      "Epoch: 98, Training Loss: 1.62, Validation Loss: 3.39, accuracy = 0.15\n",
      "Epoch: 99, Training Loss: 1.62, Validation Loss: 3.39, accuracy = 0.15\n",
      "Epoch: 100, Training Loss: 1.61, Validation Loss: 3.39, accuracy = 0.16\n"
     ]
    }
   ],
   "source": [
    "train(audionet, optimizer, torch.nn.CrossEntropyLoss(),train_loader, valid_loader, epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-alias",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
